# WQ Research Agent

A research-oriented agent framework for quantitative alpha analysis, built on top of OpenAI function calling and a Postgres-backed data layer.

This project focuses on **deterministic, tool-driven research workflows**, rather than free-form LLM chat.

---

## üöÄ Overview

This agent is designed to:

- Query and analyze quantitative alpha data stored in Postgres
- Use LLMs **only for decision-making and tool selection**
- Enforce strict tool usage rules to avoid ambiguous or unsafe calls
- Support scalable research workflows (list ‚Üí inspect ‚Üí simulate ‚Üí evaluate)

Core philosophy:

> **LLM decides *what* to do, code decides *how* to do it.**

---

## üß† Architecture

‚îú‚îÄ‚îÄ run_agent.py          # Agent main loop (LLM + tool dispatch)
‚îú‚îÄ‚îÄ agent_prompt.py       # Base agent / system prompt
‚îú‚îÄ‚îÄ RESEARCH_PROMPT.py    # Strict research prompt template
‚îú‚îÄ‚îÄ registry.py           # Tool registry & schemas
‚îú‚îÄ‚îÄ db.py                 # Postgres connection & query helpers
‚îú‚îÄ‚îÄ tools/                # Concrete research tools
‚îÇ   ‚îú‚îÄ‚îÄ get_alpha_detail.py
‚îÇ   ‚îú‚îÄ‚îÄ get_backtest_metrics.py
‚îÇ   ‚îú‚îÄ‚îÄ list_alphas.py
‚îÇ   ‚îú‚îÄ‚îÄ resolve_cutoff.py
‚îÇ   ‚îî‚îÄ‚îÄ simulate_alpha.py


### Separation of responsibilities

- **Prompt layer**
  - Defines strict rules for tool usage
  - Prevents hallucinated or partial tool calls

- **Tool layer**
  - Each tool corresponds to a concrete, deterministic action
  - Backed by SQL queries or simulation logic

- **Agent loop**
  - Parses LLM output
  - Validates / patches tool arguments
  - Executes tools and feeds results back

---

## üõ†Ô∏è Tools (Current)

| Tool | Description |
|-----|------------|
| `list_alphas` | List available alpha IDs |
| `get_alpha_detail` | Fetch alpha expression & metadata |
| `get_backtest_metrics` | Retrieve performance metrics (Sharpe, etc.) |
| `simulate_alpha` | Run alpha simulation |
| `resolve_cutoff` | Resolve backtest cutoffs / constraints |

> All tools are registered centrally in `registry.py`.

---

## üß™ Prompt Design

The agent uses a **strict research prompt** that enforces:

- No tool calls with missing parameters
- No empty `{}` arguments
- No fabricated values
- Mandatory clarification if required inputs are missing

This avoids a common failure mode of LLM-based agents:  
*calling the right tool with the wrong (or empty) arguments*.

---

## üóÑÔ∏è Database

- Backend: **Postgres**
- Connection configured via environment variables:

```bash
export PG_HOST=localhost
export PG_DB=wq
export PG_USER=postgres
export PG_PASSWORD=postgres

All database access is centralized in db.py.

‚ñ∂Ô∏è Running the Agent

Activate your virtual environment, then:

python run_agent.py

Example user query handled by the agent:
Show me details of alpha A123

The agent will:
	1.	Decide which tool to use
	2.	Validate arguments
	3.	Query Postgres
	4.	Return structured results


‚ö†Ô∏è Design Notes
	‚Ä¢	This is not a chat-bot
	‚Ä¢	This is not a LangChain-style autonomous agent
	‚Ä¢	Determinism and reproducibility are prioritized over autonomy
	‚Ä¢	Fallback logic exists at the code level to guarantee correctness

üîÆ Roadmap

Planned extensions:
	‚Ä¢	Research-oriented tools (ranking, filtering, top-k selection)
	‚Ä¢	Tool planning (multi-step research flows)
	‚Ä¢	Alpha comparison and decision support
	‚Ä¢	Batch research and evaluation pipelines

